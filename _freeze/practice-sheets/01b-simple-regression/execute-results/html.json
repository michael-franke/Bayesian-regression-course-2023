{
  "hash": "f6b023b8c385c3e9cc4129b40c91821b",
  "result": {
    "markdown": "---\ntitle: \"Bayesian regression: theory & practice\"\nsubtitle: \"01b: Simple linear regression\"\nauthor: \"Michael Franke & Timo Roettger\"\nformat: html\neditor: visual\nexecute:\n  error: false\n  warning: false\n  message: false\ncallout-appearance: simple\n---\nHere is code to load (and if necessary, install) required packages, and to set some global options (for plotting and efficient fitting of Bayesian models).\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# install packages from CRAN (unless installed)\npckgs_needed <- c(\n  \"tidyverse\",\n  \"brms\",\n  \"remotes\",\n  \"tidybayes\"\n)\npckgs_installed <- installed.packages()[,\"Package\"]\npckgs_2_install <- pckgs_needed[!(pckgs_needed %in% pckgs_installed)]\nif(length(pckgs_2_install)) {\n  install.packages(pckgs_2_install)\n} \n\n# install additional packages from GitHub (unless installed)\nif (! \"aida\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/aida-package\")\n}\nif (! \"faintr\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/faintr\")\n}\nif (! \"cspplot\" %in% pckgs_installed) {\n  remotes::install_github(\"CogSciPrag/cspplot\")\n}\n\n# load the required packages\nx <- lapply(pckgs_needed, library, character.only = TRUE)\nlibrary(aida)\nlibrary(faintr)\nlibrary(cspplot)\n\n# these options help Stan run faster\noptions(mc.cores = parallel::detectCores())\n\n# use the CSP-theme for plotting\ntheme_set(theme_csp())\n\n# global color scheme from CSP\nproject_colors = cspplot::list_colors()[c(1,3,4,5,2,6:14),\"hex\", drop = TRUE]\n\n# setting theme colors globally\nscale_colour_discrete <- function(...) {\n  scale_colour_manual(..., values = project_colors)\n}\nscale_fill_discrete <- function(...) {\n   scale_fill_manual(..., values = project_colors)\n}\n```\n:::\n\n\n\n# Simple linear regression\n\nLet's use the `dolphin` data set to practice Bayesian linear regression modeling.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin <- aida::data_MT\n```\n:::\n\n\nLet's start by asking: **how is the area-under-the-curve (AUC) related to the maximum absolute deviation (MAD)?** We could hypothesize that they are strongly related, right? The more the cursor strives toward the competitor, the larger is the overall area under the curve.\n\nFirst, we will massage the data a little bit. We only want to look at those rows in which the participant selected the correct response. And instead of looking at all the data, we will only deal with the median values for each participant. In this way, we get a more robust signal (but really we do this here for more practical purposes (faster fitting, less clutter)).\n\n## Data wrangling\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# aggregate\ndolphin_agg <- dolphin |> \n  filter(correct == 1) |> \n  group_by(subject_id) |> \n  dplyr::summarize(\n            AUC = median(AUC, na.rm = TRUE),\n            MAD = median(MAD, na.rm = TRUE)) \n  \n# let's have a look\nhead(dolphin_agg)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  subject_id     AUC    MAD\n       <dbl>   <dbl>  <dbl>\n1       1001  55200. 111.  \n2       1002  59596.  87.9 \n3       1003 -17772  -34.1 \n4       1004  -3600.  -3.83\n5       1005  54054   95.0 \n6       1006  60396. 155.  \n```\n:::\n:::\n\n\n## Visual assessment\n\nBefore we start thinking about statistical inference, we always want to get a feel for the data visually. You basically always want to plot the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot\nggplot(data = dolphin_agg, \n       aes(x = MAD, \n           y = AUC)) + \n  geom_point(size = 3, alpha = 0.3) \n```\n\n::: {.cell-output-display}\n![](01b-simple-regression_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nThis graph displays the distribution of AUC and MAD values.\n\nLooking at the plot, we can see that there is a strong relationship between AUC and MAD. And that makes a lot of sense. The larger the cursor strives toward the competitor, the larger is the overall area under the curve. Heureka! Our hypothesis is confirmed.\n\nBut wait! As Bayesians, we would like to translate the data into an expression of **evidence**: do the data provide evidence for our research hypotheses? Also, notice that there is some variability. We want precise estimates of potential effects. We also want a measure of how certain we can be about these estimates.\n\n## Bayesian linear regression with `brms`\n\nThe `brms` package allows us to run Bayesian regression models, both simple and rather complex. It uses a sampling method, so its output will be vectors of (corellated) samples from the posterior distribution of the model's parameters. (We will learn how this sampling method works later).\n\nSo, to quantify evidence and uncertainty with posterior samples, let's run a simple linear regression model using `brms`. We use the R notation that some of your might already be familiar with when using `lm()`. We specify a formula in which AUC is predicted by MAD.\n\n`AUC ~ MAD`\n\nWhen you run this code, the `brms` package generates Stan code and runs the Stan program in the background. Stan code is executed in C++, and the model will be 'compiled' (you get information about this in the console output). We will learn later what this compilation does (spoiler: it computes gradients for all stochastic nodes in the model). The only thing that is relevant for you at the moment is this: This compilation can take quite a while (especially for complex models) before anything happens.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# specify the model \nmodel1 = brm(\n  # model formula\n  AUC ~ MAD, \n  # data\n  data = dolphin_agg\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: AUC ~ MAD \n   Data: dolphin_agg (Number of observations: 108) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept   520.92   1864.46 -3067.74  4283.67 1.00     3930     2777\nMAD         454.82     16.38   423.17   487.37 1.00     3592     2678\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma 17188.92   1187.23 15028.28 19783.40 1.00     3625     2676\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nThe output of such a model looks very familiar if you have worked with lm() before. We want to look at what is here called \"Population-Level Effects\", which is a small table in this case. The first column contains the names of our coefficients; the `Estimate` column gives us the posterior mean of these coefficients; the `Est.Error` give us the standard error; the `l-95%`and `u-95%` give us the lower and upper limit of the 95% Credible Interval (henceforth CrI). The column `Rhat` (R\\^) which is a diagnostic of chain convergence and should not diverge much from 1 (rule of thumb: should by \\<1.1). Again, more about that later. The `Bulk_ESS` and `Tail_ESS` columns give us numbers of \"useful\" samples. This number should be sufficiently high. If its not, `brms` will give you a convenient warning (more about that later, so don't worry for now). If that happens, you need to increase the chains and / or the number of iterations in order to increase the overall number of samples (again, don't worry for now).\n\nIf we need the main summary output in a tidy tibble format, we can use this function from the `tidybayes` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidybayes::summarise_draws(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 10\n  variable    mean  median      sd     mad      q5     q95  rhat ess_b…¹ ess_t…²\n  <chr>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>\n1 b_Inter…   521.    493.  1.86e+3 1.81e+3 -2486.   3596.   1.00   3930.   2777.\n2 b_MAD      455.    455.  1.64e+1 1.64e+1   428.    482.   1.00   3592.   2678.\n3 sigma    17189.  17118.  1.19e+3 1.16e+3 15375.  19280.   1.00   3625.   2676.\n4 lprior     -22.3   -22.3 2.98e-2 2.83e-2   -22.4   -22.3  1.00   3598.   2579.\n5 lp__     -1218.  -1218.  1.23e+0 9.96e-1 -1221.  -1217.   1.00   1778.   2714.\n# … with abbreviated variable names ¹​ess_bulk, ²​ess_tail\n```\n:::\n:::\n\n\nThe model output suggests that the posterior mean of the Intercept is around 521 . The coefficient for MAD is estimated to be about 455.\n\nTo see how good a fit this is, we should manually draw this line into the graph from above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract model parameters:\nmodel_intercept <- summary(model1)$fixed[1,1]\nmodel_slope <- summary(model1)$fixed[2,1]\n\n# plot\nggplot(data = dolphin_agg, \n       aes(x = MAD, \n           y = AUC)) + \n  geom_abline(intercept = model_intercept, slope = model_slope, color = project_colors[2], size  = 1) +\n  geom_point(size = 3, alpha = 0.3, color = project_colors[1])\n```\n\n::: {.cell-output-display}\n![](01b-simple-regression_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nLooking at the graph, it does make sense, right? The red line seems to capture the main trend pretty well.\n\nNow is there a relationship between AUC and MAD? What would it mean if there was *no* relationship between these two measures? Well no relationship would mean a slope of 0. How would that look like?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = dolphin_agg, \n       aes(x = MAD, \n           y = AUC)) + \n  geom_abline(intercept = model_intercept, slope = model_slope, color = project_colors[2], size = 1) +\n  geom_abline(intercept = model_intercept, slope = 0, color = project_colors[3], size = 1, lty = \"dashed\") +\n  geom_point(size = 3, alpha = 0.3, color = project_colors[1])\n```\n\n::: {.cell-output-display}\n![](01b-simple-regression_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nThese lines look quite different indeed. But Bayesian data analysis does not give us only one single line. It gives us *infinitely many* lines, weighted by plausibility. Let's explore this universe of weighted predictions.\n\n## Extracting posterior distributions and plotting them\n\nWe can interpret and visualize our coefficients immediately. We can create a data frame with all posterior samples for each parameter and plot those distributions for all coefficients. Let's first see what coefficients there are with the `get_variables()` function from the `tidybayes` package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# inspect parameters\ntidybayes::get_variables(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"b_Intercept\"   \"b_MAD\"         \"sigma\"         \"lprior\"       \n [5] \"lp__\"          \"accept_stat__\" \"stepsize__\"    \"treedepth__\"  \n [9] \"n_leapfrog__\"  \"divergent__\"   \"energy__\"     \n```\n:::\n:::\n\n\nEverything that is preceded by a `b_` is a population level coefficients, i.e. our predictors. Now let's wrangle this data frame to get what we need. You don't have to entirely understand the following code, but make sure you understand it well enough to recycle it later on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wrangle data frame\nposteriors1 <- model1 |>\n  tidybayes::spread_draws(b_MAD, b_Intercept) |>\n  select(b_MAD, b_Intercept)\n\nposteriors1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,000 × 2\n   b_MAD b_Intercept\n   <dbl>       <dbl>\n 1  456.     -2453. \n 2  459.      1607. \n 3  466.     -1022. \n 4  435.      2038. \n 5  451.       144. \n 6  451.       144. \n 7  455.       910. \n 8  467.       445. \n 9  437.      1006. \n10  451.        17.3\n# … with 3,990 more rows\n```\n:::\n:::\n\n\nNow that we know how to extract posterior samples, let's actually take a bunch of these samples and plot them as lines into our scatter plot from above. In this code chunk we generate a subsample of 100 parameter pairs.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# wrangle data frame\nposteriors2 <- model1 |>\n  # parameter 'ndraws' requests 100 random subsamples\n  tidybayes::spread_draws(b_MAD, b_Intercept, ndraws = 100) |>\n  select(b_MAD, b_Intercept)\n  \n# plot\nggplot(data = dolphin_agg, \n       aes(x = MAD, \n           y = AUC)) + \n  geom_abline(data = posteriors2,\n              aes(intercept = b_Intercept, slope = b_MAD), \n              color = project_colors[2], size  = 0.1, alpha = 0.4) +\n  geom_point(size = 3, alpha = 0.3, color = project_colors[1]) +\n  theme_aida()\n```\n\n::: {.cell-output-display}\n![](01b-simple-regression_files/figure-html/regressionLines-1.png){fig-align='center' width=480}\n:::\n:::\n\n\nGiven our model, assumptions and data, these are 100 plausible regression lines. As you can see they are very similar.\n\nUsing this pipeline we can also calculate the mean of the posteriors and any kind of Credible Interval (CrI). We first extract the posterior and bring them into a tidy form. Let's only look at the coefficient for MAD here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposteriors3 <- model1 |>\n   # use the gather_draws() function for \"long data\"\n   tidybayes::gather_draws(b_MAD) |> \n   # change names of columns\n   rename(parameter = .variable,\n          posterior = .value) |> \n   # select only those columns that are relevant\n   select(parameter, posterior)\n\nhead(posteriors3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 2\n# Groups:   parameter [1]\n  parameter posterior\n  <chr>         <dbl>\n1 b_MAD          456.\n2 b_MAD          459.\n3 b_MAD          466.\n4 b_MAD          435.\n5 b_MAD          451.\n6 b_MAD          451.\n```\n:::\n:::\n\n\nAnd then calculate the mean, the lower and the upper bound of a 90% CrI, using the function `tidybayes::hdi()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get posteriors for the relevant coefficients\nposteriors3_agg <- posteriors3 |> \n  group_by(parameter) |> \n  summarise(\n    `90lowerCrI`   = tidybayes::hdi(posterior, credMass = 0.90)[1],\n    mean_posterior = mean(posterior),\n    `90higherCrI`  = tidybayes::hdi(posterior, credMass = 0.90)[2])\n\nposteriors3_agg \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 4\n  parameter `90lowerCrI` mean_posterior `90higherCrI`\n  <chr>            <dbl>          <dbl>         <dbl>\n1 b_MAD             422.           455.          486.\n```\n:::\n:::\n\n\nNow we use this newly created data frame to plot the posterior distributions of all population-level coefficients. Again, we use our new best friend, the `tidybayes` package which offers some sweet extensions to `ggplot`'s `geom_` family of functions. We also add a reference point to compare the posteriors against. A common and reasonable reference point is 0. Remember a slope coefficient of zero would correspond to a flat regression line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot the regression coefficients\nposteriors1 |> \n  pivot_longer(cols = everything(), names_to = \"parameter\", values_to = \"posterior\") |> \n  ggplot(aes(x = posterior, y = parameter, fill = parameter)) + \n    # plot density w/ 90% credible interval\n    tidybayes::stat_halfeye(.width = 0.9) +\n    # add axes titles\n    xlab(\"\") +\n    ylab(\"\") +\n    # adjust the x-axis \n    scale_x_continuous(limits = c(-100,600)) +\n    # add line for the value zero\n    geom_segment(x = 0, xend = 0, y = Inf, yend = -Inf,\n                 lty = \"dashed\") +\n    theme(legend.position=\"none\")\n```\n\n::: {.cell-output-display}\n![](01b-simple-regression_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\nposteriors3_agg[1,2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  `90lowerCrI`\n         <dbl>\n1         422.\n```\n:::\n:::\n\n\nHere you see density plots for our critical coefficients of the model. We care mostly about the slope coefficient (b_MAD) (the posterior of which is shown in red). Values between about 422.315603 and about 486.1069995 are plausible (at the 90% level) and they are indicated by the thick black line in the density plot for this coefficient. The mean of the distribution is indicated by the thick black dot.\n\nThat's helpful because we can relate this distribution to relevant values, for example the value 0 (dashed line). If you look at the coefficient, you can see that the posterior distribution does not include the value zero or any small-ish \"Region of Practical Equivalence\" around it. In fact, the posterior is really far away from zero. Thus, if we believe in the data and the model, we can be very certain that this coefficient is not zero. In other words, we would be very certain that there is a positive relationship between AUC and MAD (and in turn that 'no relationship' is not a very plausible scenario).\n\nThe `brms` package allows us to quickly evaluate how many posterior samples fall into a certain value range. Just for fun, let's calculate the amount of posterior samples that are larger than 450. The following code chunk does this for us:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhypothesis(model1, 'MAD > 450')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHypothesis Tests for class b:\n       Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob\n1 (MAD)-(450) > 0     4.82     16.38   -22.05    32.36        1.6      0.62\n  Star\n1     \n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n:::\n:::\n\n\nThe results tell us that more than 60% of all posterior samples are larger than 450. It also tells us the evidence ratio (more on this later), which is the odds of the hypothesis in question (here 'MAD \\> 450).\n\n## Exercises for simple regression modeling\n\n::: callout-caution\n**Exercise 1a**\n\nMassage the data and create a new dataset that contains only correct responses and only the mean values of the RT and the AUC measurement for each participant (`subject_id`). Print out the `head` of the dataset.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# aggregate\ndolphin_agg <- dolphin |> \n  filter(correct == 1) |> \n  group_by(subject_id) |> \n  dplyr::summarize(AUC = mean(AUC, na.rm = TRUE),\n            RT = mean(RT, na.rm = TRUE))\n  \n# let's have a look\nhead(dolphin_agg)\n```\n:::\n\n\nWe know from the previous exercises (walkthrough) that the area-under-the-curve (AUC) is related to the maximum absolute deviation (MAD). But what about reaction times (RTs)? Isn't it plausible that RTs are also related to AUC? The further I curve away from the target with the cursor, the longer it takes me to arrive at the target, right?\n\n::: callout-caution\n**Exercise 1b**\n\nPlot the relationship between RT and AUC in a scatterplot.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# plot\nggplot(data = dolphin_agg, \n       aes(x = RT, \n           y = AUC)) + \n  geom_point(size = 3, alpha = 0.3)\n```\n:::\n\n\n::: callout-caution\n**Exercise 1c**\n\nRun a linear regression using `brms`. AUC is the dependent variable (i.e. the measure) and RT is the independent variables (i.e. the predictor). The formula writes: `AUC ~ RT`\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# specify the model \nmodel1 <- brm(\n  # model formula\n  AUC ~ RT, \n  # data\n  data = dolphin_agg\n  )\n\nsummary(model1)\n```\n:::\n\n\n::: callout-caution\n**Exercise 1d**\n\nLook at the model output. Think of it in terms of a line in the scatterplot from (1b). Where does the regression line cross the y-axis, what is the slope of the line? Draw a scatterplot of AUC against RT and add the predicted values as a line.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# extract model parameters:\nmodel_intercept <- summary(model1)$fixed[1,1]\nmodel_slope <- summary(model1)$fixed[2,1]\n\n# plot\nggplot(data = dolphin_agg, \n       aes(x = RT, \n           y = AUC)) + \n  geom_abline(aes(intercept = model_intercept, slope = model_slope),\n              color = project_colors[2], size = 2) +\n  geom_point(size = 3, alpha = 0.3)\n```\n:::\n\n\nThat doesn't really look like a tight linear relationship, right? If there is any relationship, AUC values become lower with longer reaction times (the line has a negative slope).\n\n::: callout-caution\n**Exercise 1e**\n\nNow create a new data frame which contains the extracted posteriors for `b_RT` from the model output (use the `spread_draws()` function). Print out the `head` of the new dataset.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# get posteriors for the relevant coefficients\nposteriors1 <- model1 |>\n  # use the spread_draws() function of tidybayes for all relevant parameters\n  spread_draws(b_RT) |>\n  # select only those columns that are relevant\n  select(b_RT) |> \n  # bring into long format\n  gather(key = \"parameter\", value = \"posterior\")\n  \nhead(posteriors1)\n```\n:::\n\n\n::: callout-caution\n**Exercise 1f**\n\nPlot the results with the \\`geom_halfeyeh() function. Add a vertical line at zero.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# plot the regression coefficients\n  ggplot(posteriors1, aes(x = posterior, y = parameter)) + \n    # plot density \n    tidybayes::stat_halfeye(.width = 0.95) +\n    # add axes titles\n    xlab(\"\\nb_RT posterior distribution\") +\n    ylab(\"\") +\n    # adjust the x-axis \n    scale_x_continuous(expand = c(0, 0), limits = c(-100,100)) +\n    # add line for the value zero\n    geom_segment(x = 0, xend = 0, y = Inf, yend = -Inf,\n                 lty = \"dashed\")\n```\n:::\n\n\nNow: What is the picture telling us? Is there reason to believe in a relationship between AUC and RT? Think about it!\n\nThere is no compelling support for a belief in a relationship between AUC and RT. The value zero (no relationship) is contained in the 95% CrI and a non-trivial amount of posterior samples is larger than 0.\n",
    "supporting": [
      "01b-simple-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}