{
  "hash": "454b56195dca11ce781a404ac3fb0814",
  "result": {
    "markdown": "---\ntitle: \"Bayesian regression: theory & practice\"\nsubtitle: \"04a: MCMC diagnostics (demonstrations)\"\nauthor: \"Michael Franke\"\nformat: html\neditor: visual\nexecute:\n  error: false\n  warning: false\n  message: false\ncallout-appearance: simple\n---\n\n  \nLoad relevant packages and \"set the scene.\"\n  \nHere is code to load (and if necessary, install) required packages, and to set some global options (for plotting and efficient fitting of Bayesian models).\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# install packages from CRAN (unless installed)\npckgs_needed <- c(\n  \"tidyverse\",\n  \"brms\",\n  \"remotes\",\n  \"tidybayes\",\n  \"shinystan\"\n)\npckgs_installed <- installed.packages()[,\"Package\"]\npckgs_2_install <- pckgs_needed[!(pckgs_needed %in% pckgs_installed)]\nif(length(pckgs_2_install)) {\n  install.packages(pckgs_2_install)\n} \n\n# install additional packages from GitHub (unless installed)\nif (! \"aida\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/aida-package\")\n}\nif (! \"faintr\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/faintr\")\n}\nif (! \"cspplot\" %in% pckgs_installed) {\n  remotes::install_github(\"CogSciPrag/cspplot\")\n}\n\n# load the required packages\nx <- lapply(pckgs_needed, library, character.only = TRUE)\nlibrary(aida)\nlibrary(faintr)\nlibrary(cspplot)\n\n# these options help Stan run faster\noptions(mc.cores = parallel::detectCores())\n\n# use the CSP-theme for plotting\ntheme_set(theme_csp())\n\n# global color scheme from CSP\nproject_colors = cspplot::list_colors()[c(1,3,4,5,2,6:14),\"hex\", drop = TRUE]\n\n# setting theme colors globally\nscale_colour_discrete <- function(...) {\n  scale_colour_manual(..., values = project_colors)\n}\nscale_fill_discrete <- function(...) {\n   scale_fill_manual(..., values = project_colors)\n}\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin <- aida::data_MT\nmy_scale <- function(x) c(scale(x))\n```\n:::\n\n  \nThis tutorial provides demonstrations of how to check the quality of MCMC samples obtained from `brms` model fits.\n  \n# A good model\n \nTo have something to go on, here are two model fits, one of this is good, the other is ... total crap. The first model fits a smooth line to the average world temperature. (We need to set the seed here to have reproducible results.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_good <- brm(\n  formula = avg_temp ~ s(year), \n  data = aida::data_WorldTemp,\n  seed = 1969\n) \n```\n:::\n\n\nThe good model is rather well behaved. Here is a generic plot of its posterior fits and traceplots:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit_good)\n```\n\n::: {.cell-output-display}\n![](04a-MCMC-diagnostics_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nTraceplots look like madly-in-love caterpillars doing their thing.\n\nWe can check $\\hat{R}$ and effective sample sizes also in the summary of the model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_good)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: avg_temp ~ s(year) \n   Data: aida::data_WorldTemp (Number of observations: 269) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nSmooth Terms: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsds(syear_1)     3.56      1.08     1.96     6.17 1.00      907     1689\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     8.31      0.02     8.27     8.35 1.00     3732     2652\nsyear_1      14.55      2.25    10.11    19.08 1.00     2182     2371\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.33      0.01     0.30     0.36 1.00     3823     2962\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nInterestingly, there is one warning message about one divergent transition. We are recommended to check the `pairs()` plot, so here goes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit_good)\n```\n\n::: {.cell-output-display}\n![](04a-MCMC-diagnostics_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThis is actually not too bad. (Wait until you see a terrible case below!)\n\nWe can try to fix this problem with a single divergent transition by doing as recommended by the warning message, namely increasing the `adapt_delta` parameter in the `control` structure:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_good_adapt <- brm(\n  formula = avg_temp ~ s(year), \n  data = aida::data_WorldTemp,\n  seed = 1969,\n  control = list(adapt_delta=0.9),\n) \n\nsummary(fit_good_adapt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: avg_temp ~ s(year) \n   Data: aida::data_WorldTemp (Number of observations: 269) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nSmooth Terms: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsds(syear_1)     3.59      1.09     1.97     6.30 1.00     1003     1613\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     8.31      0.02     8.27     8.35 1.00     3632     2619\nsyear_1      14.59      2.40     9.96    19.34 1.00     2425     2510\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.33      0.01     0.30     0.36 1.00     3588     2868\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nThat looks better, but what did we just do? --- When the sampler \"warms up\", it tries to find good parameter values for the case at hand. The `adapt_delta` parameter is the minimum amount of accepted proposals (where to jump next) before \"warm up\" counts as done and successfull. So with a small problem like this, just making the adaptation more ambitious may have have solved the problem. It has also, however, made the sampling slower, less efficient.\n\nA powerful interactive tool for exploring a fitted model (diagnostics and more) is `shinystan`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshinystan::launch_shinystan(fit_good_adapt)\n```\n:::\n\n\n# A terrible model \n\nThe main (maybe only) reason for serious problems with the NUTS sampling is this: **sampling issues arise for bad models**. So, let's come up with a really stupid model.\n\nHere's a model that is like the previous but adds a second predictor, which is a normal (non-smoothed) regression coefficient that is almost identical to the original `year` information. You may already intuit that this cannot possibly be a good idea; the model is notionally deficient. So, we exepct nightmares during sampling:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_bad <- brm(\n  formula = avg_temp ~ s(year) + year_perturbed, \n  data = aida::data_WorldTemp |> mutate(year_perturbed = rnorm(1,year,0.001)),\n  seed = 1969\n) \n\nsummary(fit_bad)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: avg_temp ~ s(year) + year_perturbed \n   Data: mutate(aida::data_WorldTemp, year_perturbed = rnor (Number of observations: 269) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nSmooth Terms: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsds(syear_1)     3.62      1.09     2.01     6.24 1.00     1239     1594\n\nPopulation-Level Effects: \n                       Estimate        Est.Error          l-95% CI\nIntercept      2225135220368.58 2790632812490.53 -1139137522767.06\nyear_perturbed   -1271506170.07    1594647735.12    -4693478867.37\nsyear_1                   14.53             2.32             10.16\n                       u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      8213585887067.27 1.76        6       35\nyear_perturbed     650935896.17 1.76        6       35\nsyear_1                   19.27 1.00     2285     2953\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.33      0.01     0.30     0.36 1.00     4150     2656\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nIndeed, that looks pretty bad. We managed to score badly on all major accounts:\n\n- large $\\hat{R}$\n- extremely poor efficient sample size\n- ridiculously far ranging posterior estimates for the main model components\n- tons of divergent transitions\n- maximum treedepth reached more often than hipster touches their phone in a week\n\nSome of these caterpillars look like they are in a vicious rose war:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(fit_bad)\n```\n\n::: {.cell-output-display}\n![](04a-MCMC-diagnostics_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nWe also see that that the intercept of and the slope for `year_perturbed` are the main troublemakers (in terms of traceplots).\n\nInterestingly, a simple posterior check doesn't look half-bad:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(fit_bad)\n```\n\n::: {.cell-output-display}\n![](04a-MCMC-diagnostics_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nBut now, have a look at the `pairs()` plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit_bad)\n```\n\n::: {.cell-output-display}\n![](04a-MCMC-diagnostics_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nAha, there we see a clear problem! The joint posterior for the intercept and the slope for `year_perturbed` looks like a line. This means that these parameters could in princple do the same \"job\". \n\nThis suggests a possible solution stragey. The model is too unconstrained. It can allow these two parameters meander to wherever they want (or so it seems). We could therefore try honing them in by specifying priors, like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_bad_wPrior <- brm(\n  formula = avg_temp ~ s(year) + year_perturbed, \n  data = aida::data_WorldTemp |> mutate(year_perturbed = rnorm(1,year,0.001)),\n  seed = 1969,\n  prior = prior(\"student_t(1,0,5)\", coef = \"year_perturbed\")\n) \n\nsummary(fit_bad_wPrior)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: avg_temp ~ s(year) + year_perturbed \n   Data: mutate(aida::data_WorldTemp, year_perturbed = rnor (Number of observations: 269) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nSmooth Terms: \n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsds(syear_1)     3.62      1.08     2.04     6.16 1.00     1074     1808\n\nPopulation-Level Effects: \n               Estimate Est.Error  l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept       -187.55  58370.12 -91895.80 96032.53 1.02     2239      613\nyear_perturbed     0.11     33.35    -54.87    52.52 1.02     2239      613\nsyear_1           14.60      2.32      9.93    19.16 1.00     2006     2539\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.33      0.01     0.30     0.36 1.00     3180     2729\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nWell, alright! That isn't too bad anymore. But it is still clear from the posterior `pairs` plot that this model has two parameters that steal each other's show. The model remains a bad model ... for our data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit_bad)\n```\n\n::: {.cell-output-display}\n![](04a-MCMC-diagnostics_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nHere's what's wrong: `year_perturbed` is a constant! The model is a crappy model of the data, because the data is not what we thought it would be. Check it out:\n\n\n::: {.cell}\n\n```{.r .cell-code}\naida::data_WorldTemp |> mutate(year_perturbed = rnorm(1,year,0.001))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 269 × 5\n    year anomaly uncertainty avg_temp year_perturbed\n   <dbl>   <dbl>       <dbl>    <dbl>          <dbl>\n 1  1750  -1.41        NA        7.20          1750.\n 2  1751  -1.52        NA        7.09          1750.\n 3  1753  -1.07         1.3      7.54          1750.\n 4  1754  -0.614        1.09     8.00          1750.\n 5  1755  -0.823        1.24     7.79          1750.\n 6  1756  -0.547        1.28     8.06          1750.\n 7  1757  -0.438        1.31     8.17          1750.\n 8  1758  -2.42         1.76     6.19          1750.\n 9  1759  -1.53         2.25     7.08          1750.\n10  1760  -2.46         2.75     6.14          1750.\n# … with 259 more rows\n```\n:::\n:::\n\n\nSo, we basically ran a model with two intercepts!?!\n\nLet's try again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_WorldTemp_perturbed <- aida::data_WorldTemp |> \n    mutate(year_perturbed = rnorm(nrow(aida::data_WorldTemp),year, 50))\ndata_WorldTemp_perturbed\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 269 × 5\n    year anomaly uncertainty avg_temp year_perturbed\n   <dbl>   <dbl>       <dbl>    <dbl>          <dbl>\n 1  1750  -1.41        NA        7.20          1813.\n 2  1751  -1.52        NA        7.09          1697.\n 3  1753  -1.07         1.3      7.54          1688.\n 4  1754  -0.614        1.09     8.00          1675.\n 5  1755  -0.823        1.24     7.79          1687.\n 6  1756  -0.547        1.28     8.06          1778.\n 7  1757  -0.438        1.31     8.17          1674.\n 8  1758  -2.42         1.76     6.19          1766.\n 9  1759  -1.53         2.25     7.08          1672.\n10  1760  -2.46         2.75     6.14          1806.\n# … with 259 more rows\n```\n:::\n:::\n\n\nThat's more like what we thought it was: `year_perturbed` is supposed to be noisy version of the actual year. So, let's try again, leaving out the smoothing, just for some more chaos-loving fun:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_bad_2 <- brm(\n  formula = avg_temp ~ year + year_perturbed, \n  data = data_WorldTemp_perturbed,\n  seed = 1969,\n  prior = prior(\"student_t(1,0,5)\", coef = \"year_perturbed\")\n) \n\nsummary(fit_bad_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: avg_temp ~ year + year_perturbed \n   Data: data_WorldTemp_perturbed (Number of observations: 269) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept         -3.45      0.58    -4.58    -2.32 1.00     4456     3133\nyear               0.01      0.00     0.01     0.01 1.00     4059     2558\nyear_perturbed    -0.00      0.00    -0.00     0.00 1.00     4094     2708\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.40      0.02     0.37     0.44 1.00     1456     1573\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nThere are no warnings, so this model *must* be good, right? -- No!\n\nIf we check the pairs plot, we see that we now have introduced a fair correlation between the two predictor variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(fit_bad_2)\n```\n\n::: {.cell-output-display}\n![](04a-MCMC-diagnostics_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nWe should just not have `year_perturbed`; it's nonsense, and it shows in the diagnostics.\n\nYou can diagnose more using `shinystan`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshinystan::launch_shinystan(fit_bad)\n```\n:::\n",
    "supporting": [
      "04a-MCMC-diagnostics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}