{
  "hash": "20bd54d68bc758117551f64918b2c02d",
  "result": {
    "markdown": "---\ntitle: \"Bayesian regression: theory & practice\"\nsubtitle: \"02a: Priors, and prior & posterior predictives\"\nauthor: \"Michael Franke\"\nformat: html\neditor: visual\nexecute:\n  error: false\n  warning: false\n  message: false\ncallout-appearance: simple\n---\nHere is code to load (and if necessary, install) required packages, and to set some global options (for plotting and efficient fitting of Bayesian models).\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# install packages from CRAN (unless installed)\npckgs_needed <- c(\n  \"tidyverse\",\n  \"brms\",\n  \"remotes\",\n  \"tidybayes\"\n)\npckgs_installed <- installed.packages()[,\"Package\"]\npckgs_2_install <- pckgs_needed[!(pckgs_needed %in% pckgs_installed)]\nif(length(pckgs_2_install)) {\n  install.packages(pckgs_2_install)\n} \n\n# install additional packages from GitHub (unless installed)\nif (! \"aida\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/aida-package\")\n}\nif (! \"faintr\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/faintr\")\n}\nif (! \"cspplot\" %in% pckgs_installed) {\n  remotes::install_github(\"CogSciPrag/cspplot\")\n}\n\n# load the required packages\nx <- lapply(pckgs_needed, library, character.only = TRUE)\nlibrary(aida)\nlibrary(faintr)\nlibrary(cspplot)\n\n# these options help Stan run faster\noptions(mc.cores = parallel::detectCores())\n\n# use the CSP-theme for plotting\ntheme_set(theme_csp())\n\n# global color scheme from CSP\nproject_colors = cspplot::list_colors()[c(1,3,4,5,2,6:14),\"hex\", drop = TRUE]\n\n# setting theme colors globally\nscale_colour_discrete <- function(...) {\n  scale_colour_manual(..., values = project_colors)\n}\nscale_fill_discrete <- function(...) {\n   scale_fill_manual(..., values = project_colors)\n}\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin <- aida::data_MT\n```\n:::\n\n\n# Priors in `brms` models\n\nHere is the aggregate data and a simple linear regression model we looked at before:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create aggregate data\ndolphin_agg <- dolphin |> \n  filter(correct == 1) |> \n  group_by(subject_id) |> \n  dplyr::summarize(\n            AUC = median(AUC, na.rm = TRUE),\n            MAD = median(MAD, na.rm = TRUE)) \n\n# run the model\nmodel1 = brm(\n  AUC ~ MAD, \n  data = dolphin_agg)\n```\n:::\n\n\nWe can inspect the priors used in in a model fit like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrms::prior_summary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                          prior     class coef group resp dpar nlpar lb ub\n student_t(3, 14864.2, 32772.3) Intercept                                 \n                         (flat)         b                                 \n                         (flat)         b  MAD                            \n       student_t(3, 0, 32772.3)     sigma                             0   \n       source\n      default\n      default\n (vectorized)\n      default\n```\n:::\n:::\n\n\nThis tells us that the priors for the slope coefficient for the variable `MAD` was \"flat\".\nPer default, `brms` uses so-called improper priors, i.e., not specifying any prior at all, so that every parameter value is equally weighted (even if this is not a proper probability distribution).\n\nIn contrast, `brms` /does/ use more specific, in fact rather smart, priors for the intercept and for the standard deviation.\nThese priors are informed by the data. Look:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin_agg |> pull(AUC) |> median()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 14864.25\n```\n:::\n\n```{.r .cell-code}\ndolphin_agg |> pull(AUC) |> sd()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 49258.31\n```\n:::\n:::\n\n\nWe can change the priors used to fit the model with the `prior` attribute and the `brms::prior()` function.\nHere, we set it to a normal (with ridiculously narrow)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- brm(\n  AUC ~ MAD, \n  data = dolphin_agg,\n  prior = brms::prior(normal(0,10), class = \"b\")\n)\n```\n:::\n\n\nThe `brms::prior()` function expects the prior to be specified as a Stan expression. Full documentation for this is in the [Stan Functions Reference](https://mc-stan.org/docs/functions-reference/index.html).\n\n::: callout-caution\n**Exercise 1a**\n\nFit a third model `model3` as the previous ones, but set the prior for the slope coefficient to a Student's $t$ distribution with mean 0, standard deviation 100 and one degree of freedom.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nmodel3 <- brm(\n  AUC ~ MAD, \n  data = dolphin_agg,\n  prior = brms::prior(student_t(1,0,100), class = \"b\")\n)\n```\n:::\n\n\n::: callout-caution\n**Exercise 1b**\n\nCompare the mean posteriors for all three main parameters (intercept, slope for MAD and sigma) in all three models. What effect did changing the prior on the slope parameter have for models 2 and 3? Remember that the priors for these models are quite \"unreasonable\" in the sense that they are far away from the posterior obtained for model 1.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nextract_info <- function(model_fit, label) {\n  tidybayes::summarise_draws(model_fit) |> \n    mutate(model = label) |> \n    select(model, variable, q5, mean, q95) |> \n    filter(variable %in% c('b_Intercept', 'b_MAD', 'sigma'))\n}\n\nrbind(\n  extract_info(model1, \"model 1\"),\n  extract_info(model2, \"model 2\"),\n  extract_info(model3, \"model 3\")\n) |> arrange(variable, model)\n\n# we see that the Student-t prior in model 3 gives a very similar fit as for model 1;\n#   this is likely due to the heavier tails of the Student-t distribution\n#\n# we also see that the more restricted model 2 has a much lower mean posterior \n#   for the slope coefficient (because this parameter is \"leashed close to zero\" by the prior);\n#   instead model 2 compensates with a much higher intercept estimate\n```\n:::\n\n\nThe important upshot of this exercise is that since all parameters jointly condition the likelihood function, it can happen that changing the priors for just one parameter will also affect the posterior inferences for other parameters (who have to \"go out of they way\" to compensate for what the other parameter can or cannot do, so to speak).\n\nThis raises the question of how to determine \"good priors\". This is a chapter of its own, and a controversial one, and definitely a matter that depends on what you want to do with your model (explore or monkey-around, make serious predictions about the future (e.g., disease spread, market development), or draw theoretical conclusions from data (e.g., which theory of reading-times in garden-path sentences is supported better by some data)). In almost all cases, however, it is good advice to remember this: **priors should be evaluated  in the context of the (prior) predictions they entail**. That's the topic we attend to in the next section.\n\nBefore going there, here is how we can obtain samples from the prior of a model.\nSampling from the prior only works if priors are not the improper (flat) default priors.\nFirstly, we can use the option `sample_prior = \"only\"` to obtain only samples from the prior.\n(NB: we still need to supply the data because it is used for the setting up the model; e.g., specifying the prior for the intercept.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2_priorOnly <- brm(\n  AUC ~ MAD, \n  data = dolphin_agg,\n  prior = brms::prior(normal(0,10), class = \"b\"),\n  sample_prior = 'only'\n)\n\nmodel2_priorOnly |> tidybayes::summarise_draws() |> select(1:6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 6\n  variable          mean     median       sd      mad       q5\n  <chr>            <dbl>      <dbl>    <dbl>    <dbl>    <dbl>\n1 b_Intercept 15889.     15470.     48117.   36100.   -58402. \n2 b_MAD           0.0208    -0.0138     9.82    10.2     -15.7\n3 sigma       36083.     25407.     40713.   23080.     2470. \n4 lprior        -27.3      -26.9        1.57     1.30    -30.4\n5 lp__          -17.3      -16.9        1.44     1.20    -20.2\n```\n:::\n:::\n\n\nIt is also possible to obtain a posterior fit /and/ prior samples at the same time, but that is a bit more fickle, as the prior samples will have other names, and (AFAICS) other functions are required than for posterior samples, entailing other formatting of the returned samples.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2_priorAdded <- brm(\n  AUC ~ MAD, \n  data = dolphin_agg,\n  prior = brms::prior(normal(0,10), class = \"b\"),\n  sample_prior = TRUE\n)\n\n# posterior samples\nmodel2_priorAdded |> tidybayes::summarise_draws() |> select(1:6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 × 6\n  variable             mean     median       sd      mad        q5\n  <chr>               <dbl>      <dbl>    <dbl>    <dbl>     <dbl>\n1 b_Intercept     22269.    22353.      4479.    4361.    14840.  \n2 b_MAD              21.8      21.9       10.3     10.3       4.68\n3 sigma           47453.    47240.      3406.    3245.    42163.  \n4 prior_Intercept 14932.    14991.     55039.   38042.   -62655.  \n5 prior_b            -0.134    -0.0964     9.99     9.88    -16.3 \n6 prior_sigma     35258.    24291.     40236.   23403.     2231.  \n7 lprior            -29.3     -28.8        2.30     2.11    -33.9 \n8 lp__            -1335.    -1334.         1.22     1.01  -1337.  \n```\n:::\n\n```{.r .cell-code}\n# prior samples\nbrms::prior_samples(model2_priorAdded) |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Intercept             b                 sigma         \n Min.   :-662812   Min.   :-41.05139   Min.   :     7.2  \n 1st Qu.: -10686   1st Qu.: -6.61993   1st Qu.: 11306.0  \n Median :  14991   Median : -0.09639   Median : 24290.9  \n Mean   :  14932   Mean   : -0.13402   Mean   : 35258.1  \n 3rd Qu.:  40601   3rd Qu.:  6.71574   3rd Qu.: 46648.2  \n Max.   :1021962   Max.   : 33.75663   Max.   :710366.2  \n```\n:::\n:::\n\n\nA third possibility is to use `stats::update()` to draw additional prior samples from an already fitted object, like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# this fit only contains priors but keeps them with the same names and structure\n# as the posterior samples in `model2`\nmodel2_priorUpdate <- stats::update(model2, sample_prior = \"only\")\n\nmodel2_priorUpdate |> tidybayes::summarise_draws() |> select(1:6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 6\n  variable          mean     median       sd      mad       q5\n  <chr>            <dbl>      <dbl>    <dbl>    <dbl>    <dbl>\n1 b_Intercept 12532.     14660.     51587.   37793.   -69692. \n2 b_MAD          -0.0638     0.0801     9.76    10.0     -16.1\n3 sigma       35330.     25222.     37765.   22942.     2533. \n4 lprior        -27.3      -26.9        1.60     1.36    -30.5\n5 lp__          -17.4      -17.0        1.45     1.26    -20.2\n```\n:::\n:::\n\n\n\n# Prior and posterior predictives\n\nHere is an example for how we can obtain draws from the posterior predictive distribution using `tidybayes::predicted_draws`. We are using the fit of a linear model to the (scaled) average world temperature for the year 2025 to 2024.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictPriPost <- function(prior_spec, ndraws = 1000) {\n  \n  # get the posterior fit\n  fit <- brm(\n    avg_temp ~ year,\n    prior = prior_spec,\n    data = aida::data_WorldTemp,\n    silent = TRUE,\n    refresh = 0\n  )\n  \n  # retrieve prior samples from the posterior fit\n  fit_prior_only <- update(\n    fit,\n    silent = TRUE,\n    refresh = 0,\n    sample_prior = \"only\"\n  )\n  \n  get_predictions <- function(fit_object, type = \"prior prediction\") {\n    \n    tidybayes::add_linpred_draws(\n      fit_object, \n      newdata = tibble(year = aida::data_WorldTemp$year),\n      ndraws = ndraws,\n      value = 'avg_tmp'\n    ) |> \n      ungroup() |> \n      select(year, .draw, avg_tmp) |> \n      mutate(type = type)\n    \n  }\n  \n  get_predictions(fit, \"posterior prediction\") |> \n    rbind(get_predictions(fit_prior_only, \"prior prediction\")) |> \n    mutate(type = factor(type, levels = c(\"prior prediction\", \"posterior prediction\"))) |> \n    ggplot() + \n    facet_grid(type ~ ., scales = \"free\") +\n    geom_line(aes(x = year, y = avg_tmp, group = .draw), \n              color = \"gray\", alpha = 0.3) +\n    geom_point(data = aida::data_WorldTemp, \n               aes(x = year, y = avg_temp), color = project_colors[2], size = 1, alpha = 0.8) +\n    ylab(\"average temperature\")\n}\n\nprior_baseline <- c(prior(\"normal(0, 0.02)\", class = \"b\"),\n                    prior(\"student_t(3, 8, 5)\", class = \"Intercept\"))\n\nprior_opinionated <- c(prior(\"normal(0.2, 0.05)\", class = \"b\"),\n                       prior(\"student_t(3, 8, 5)\", class = \"Intercept\"))\n\nprior_crazy <- c(prior(\"normal(-1, 0.005)\", class = \"b\"),\n                 prior(\"student_t(3, 8, 5)\", class = \"Intercept\"))\n\nplot_predictPriPost(prior_baseline)\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_predictPriPost(prior_opinionated)\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot_predictPriPost(prior_crazy)\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-12-3.png){width=672}\n:::\n:::\n\n\n::: callout-caution\n**Exercise 2**\n\nPlay around with different prior specifications, and inspect the resulting prior and posterior predictions.\n\n:::\n\nLet's have a closer look at prior and posterior predictives, and the functions that we can use to explore them.\nHere, we fit a regression model with the \"crazy priors\" from above, obtaining both posterior and prior samples for it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_posterior <- brm(\n    avg_temp ~ year,\n    prior = prior_opinionated,\n    data = aida::data_WorldTemp\n  )\n\nfit_prior <- stats::update(\n    fit_posterior,\n    sample_prior = \"only\"\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naida::data_WorldTemp |> \n  ggplot(aes(x = avg_temp)) + geom_density()\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbrms::pp_check(fit_posterior, ndraws = 50)\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbrms::pp_check(fit_prior, ndraws = 100, prefix = \"ppd\")\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n:::\n\n\n\n## New Stuff\n\nHere is the mouse-tracking data set we used previously for simple linear regression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin <- aida::data_MT\n# aggregate\ndolphin_agg <- dolphin |> \n  filter(correct == 1) |> \n  group_by(subject_id) |> \n  dplyr::summarize(\n            AUC = median(AUC, na.rm = TRUE),\n            MAD = median(MAD, na.rm = TRUE)) \n```\n:::\n\n\nHere is a plot to remind ourselves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot temperature data\n\ndolphin_agg |> \n  ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(color = project_colors[2])\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n::: callout-caution\n**Exercise 3a**\n\nObtain a model fit for `AUC ~ MAD` with a prior for the slope coefficient as a Student-t distribution with 1 degree of freedom, mean 0 and standard deviation 500.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nfit_dolphin_agg <- brm(\n  AUC ~ MAD, \n  data = dolphin_agg,\n  prior = prior(student_t(1,0,500), class = \"b\")\n  )\n```\n:::\n\n\nHere is how we can extract and plot three samples from the posterior predictive distribution.\nSo, these are three \"fake\" data sets of the same size and for the same `MAD` values as in the original data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract & plot posterior predictives\npost_pred <- tidybayes::predicted_draws(\n  object = fit_dolphin_agg,\n  newdata = dolphin_agg |> select(MAD),\n  value = \"AUC\",\n  ndraws = 3\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_pred |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_point() + \n  facet_grid(. ~ run)\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n::: callout-caution\n**Exercise 3b**\n\nChange the input to the parameter `newdata` so that we get three samples for `MAD` values 400, 500 and 600.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# extract & plot posterior predictives\npost_pred2 <- tidybayes::predicted_draws(\n  object = fit_dolphin_agg,\n  newdata = tibble(MAD = c(400, 500, 600)),\n  value = \"AUC\",\n  ndraws = 3\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_pred2 |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_point() + \n  facet_grid(. ~ run)\n```\n:::\n\n\nWe can also extract predictions for the linear predictor values like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract & plot posterior linear predictors\n\npost_lin_pred <- tidybayes::linpred_draws(\n  object = fit_dolphin_agg,\n  newdata = dolphin_agg |> select(MAD),\n  value = \"AUC\",\n  ndraws = 3\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_lin_pred |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_line() + \n  facet_grid(. ~ run)\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n::: callout-caution\n**Exercise 3c**\n\nExtract 30 samples of linear predictor lines and plot them all in one plot. Make the line plots gray and use a  low `alpha` value (slight transparency).\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\npost_lin_pred2 <- tidybayes::linpred_draws(\n  object = fit_dolphin_agg,\n  newdata = dolphin_agg |> select(MAD),\n  value = \"AUC\",\n  ndraws = 30\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_lin_pred2 |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_line(aes(group = run), color = \"gray\", alpha = 0.2)\n```\n:::\n\n\nFinally, let's look at a posterior predictive check, based on the distribution of actual / predicted `AUC` values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(fit_dolphin_agg, ndraws = 20)\n```\n\n::: {.cell-output-display}\n![](02a-predictives_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n::: callout-caution\n**Exercise 3d**\n\nRepeat all the steps from the prior predictive point of view for model `fit_dolphin_agg`,\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nfit_dolphin_agg_prior <- stats::update(fit_dolphin_agg, sample_prior = 'only')\n\npost_pred <- tidybayes::predicted_draws(\n  object = fit_dolphin_agg_prior,\n  newdata = dolphin_agg |> select(MAD),\n  value = \"AUC\",\n  ndraws = 3\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_pred |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_point(alpha = 0.5) + \n  facet_grid(. ~ run)\n\n# extract & plot posterior predictives\npost_pred2 <- tidybayes::predicted_draws(\n  object = fit_dolphin_agg_prior,\n  newdata = tibble(MAD = c(400, 500, 600)),\n  value = \"AUC\",\n  ndraws = 3\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_pred2 |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_point(alpha = 0.8) + \n  facet_grid(. ~ run)\n\n# extract & plot posterior linear predictors\n\npost_lin_pred <- tidybayes::linpred_draws(\n  object = fit_dolphin_agg_prior,\n  newdata = dolphin_agg |> select(MAD),\n  value = \"AUC\",\n  ndraws = 3\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_lin_pred |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_line() + \n  facet_grid(. ~ run)\n\npost_lin_pred2 <- tidybayes::linpred_draws(\n  object = fit_dolphin_agg_prior,\n  newdata = dolphin_agg |> select(MAD),\n  value = \"AUC\",\n  ndraws = 30\n) |> \n  ungroup() |> \n  mutate(run = str_c(\"sample \", factor(.draw))) |> \n  select(run, MAD, AUC) \n\npost_lin_pred2 |> ggplot(aes(x = MAD, y = AUC)) +\n  geom_point(data = dolphin_agg, color = project_colors[2], alpha = 0.3) +\n  geom_line(aes(group = run), color = \"gray\", alpha = 0.2)\n```\n:::\n",
    "supporting": [
      "02a-predictives_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}