{
  "hash": "5ff60b55777063044b6c159971986428",
  "result": {
    "markdown": "---\ntitle: \"Bayesian regression: theory & practice\"\nsubtitle: \"03b: Generalized linear models (exercises)\"\nauthor: \"Michael Franke & Timo Roettger\"\nformat: html\neditor: visual\nexecute:\n  error: false\n  warning: false\n  message: false\ncallout-appearance: simple\n---\nHere is code to load (and if necessary, install) required packages, and to set some global options (for plotting and efficient fitting of Bayesian models).\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# install packages from CRAN (unless installed)\npckgs_needed <- c(\n  \"tidyverse\",\n  \"brms\",\n  \"remotes\",\n  \"tidybayes\"\n)\npckgs_installed <- installed.packages()[,\"Package\"]\npckgs_2_install <- pckgs_needed[!(pckgs_needed %in% pckgs_installed)]\nif(length(pckgs_2_install)) {\n  install.packages(pckgs_2_install)\n} \n\n# install additional packages from GitHub (unless installed)\nif (! \"aida\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/aida-package\")\n}\nif (! \"faintr\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/faintr\")\n}\nif (! \"cspplot\" %in% pckgs_installed) {\n  remotes::install_github(\"CogSciPrag/cspplot\")\n}\n\n# load the required packages\nx <- lapply(pckgs_needed, library, character.only = TRUE)\nlibrary(aida)\nlibrary(faintr)\nlibrary(cspplot)\n\n# these options help Stan run faster\noptions(mc.cores = parallel::detectCores())\n\n# use the CSP-theme for plotting\ntheme_set(theme_csp())\n\n# global color scheme from CSP\nproject_colors = cspplot::list_colors()[c(1,3,4,5,2,6:14),\"hex\", drop = TRUE]\n\n# setting theme colors globally\nscale_colour_discrete <- function(...) {\n  scale_colour_manual(..., values = project_colors)\n}\nscale_fill_discrete <- function(...) {\n   scale_fill_manual(..., values = project_colors)\n}\n```\n:::\n\n\n\n# Exercise 1: logistic regression\n\nUse the following data frame:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set up data frame\ndolphin <- aida::data_MT\ndolphin_agg <- dolphin %>% \n  filter(correct == 1) %>% \n  mutate(straight = as.factor(ifelse(prototype_label == \"straight\", 1, 0)),\n         log_RT_s = scale(log(RT)))\n```\n:::\n\n\n::: callout-caution\n**Exercise 1a**\n\nPlot straight (`straight == 1`) vs. non-straight (`straight == 0`) trajectories (y-axis) against `log_RT_s` and color-code by `group`.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\ndolphin_agg$straight_numeric <- as.numeric(as.character(dolphin_agg$straight))\n\nggplot(data = dolphin_agg) +\n  geom_point(aes(x = log_RT_s, y = straight_numeric, color = group), \n             # we add a little bit of jitter to make the points better visible\n             position = position_jitter(height = 0.02), alpha = 0.2) \n```\n:::\n\n\n::: callout-caution\n**Exercise 1b**\n\nRun the appropriate generalized linear model in `brms` that predicts straight vs. non-straight trajectories based on `group`, `log_RT_s`, and their two-way interaction.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nGlmMdl <- brm(straight ~ log_RT_s * group, \n                 dolphin_agg, cores = 4,\n              family = \"bernoulli\",\n              seed = 123)\nGlmMdl\n```\n:::\n\n\n::: callout-caution\n**Exercise 1c**\n\nDescribe the model predictions based on the posterior means of the population coefficients.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# Answer: The model predicts that the log odds for the mean log_RT_s in the click group (Intercept = reference level) is 0.86. With every unit of log_RT_s these log odds become smaller by 0.23. The model predicts that the log odds for the mean log_RT_s in the touch group is 1.56 (0.86 + 0.70), i.e. much higher than in the click group. With every unit of log_RT_s these log odds become smaller by 0.22.\n\n# The baseline difference between click and touch group is compelling with more straight trajectories in the touch group. The effect of log_RT_s is also compelling with less straight trajectories for slower responses. This relationship is not compellingly modulated between the touch and the click group (virtually identical).\n```\n:::\n\n\n\n::: callout-caution\n**Exercise 1d**\n\nExtract the posteriors means and 95% CrIs for the relationships between `straight`, `log_RT_s` and `group` for representative range of `log_RT_s` values. Plot the logistic regression lines for both groups into one graph. Color code the regression lines according to `group`.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# extract posterior means for model coefficients\npredicted_values <- GlmMdl %>%\n  spread_draws(b_Intercept, b_log_RT_s, b_grouptouch, `b_log_RT_s:grouptouch`) %>%\n  # make a list of relevant value range of logRT\n  mutate(log_RT = list(seq(-3, 7, 0.2))) %>% \n  unnest(log_RT) %>%\n  # transform into proportion space\n  mutate(pred_click = plogis(b_Intercept + b_log_RT_s * log_RT),\n         pred_touch = plogis(b_Intercept + b_log_RT_s * log_RT +\n                               b_grouptouch + `b_log_RT_s:grouptouch` * log_RT)\n         ) %>%\n  group_by(log_RT) %>%\n  summarise(pred_click_m = mean(pred_click, na.rm = TRUE),\n            pred_click_low = quantile(pred_click, prob = 0.025),\n            pred_click_high = quantile(pred_click, prob = 0.975),\n            pred_touch_m = mean(pred_touch, na.rm = TRUE),\n            pred_touch_low = quantile(pred_touch, prob = 0.025),\n            pred_touch_high = quantile(pred_touch, prob = 0.975)\n            ) \n\n# plot predicted values against data\nggplot(data = predicted_values) +\n  geom_hline(yintercept = c(0,1), lty = \"dashed\", color = \"grey\") +\n  geom_point(data = dolphin_agg,\n             aes(x = log_RT_s, y = straight_numeric, color = group), \n             position = position_jitter(height = 0.02), alpha = 0.2) +\n  geom_ribbon(aes(x = log_RT, ymin = pred_click_low, ymax = pred_click_high), alpha = 0.2) +\n  geom_ribbon(aes(x = log_RT, ymin = pred_touch_low, ymax = pred_touch_high), alpha = 0.2) +\n  geom_line(aes(x = log_RT, y = pred_click_m), color = \"#E69F00\", size = 2) +\n  geom_line(aes(x = log_RT, y = pred_touch_m), color = \"#56B4E9\", size = 2) +\n  ylab(\"Predicted prob of straight trajs\") +\n  ylim(-0.3,1.3) +\n  xlim(-3,7)\n```\n:::\n\n\n::: callout-caution\n**Exercise 1e**\n\nAssume we want to predict `correct` responses based on `condition`. We look at the touch group only. Set up a data frame and plot the data as a point plot. (Remember how to jitter the data points)\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# set up data frame\ndolphin_agg2 <- dolphin %>% \n filter(group == \"touch\")\n\ndolphin_agg2$correct_numeric <- as.numeric(as.character(dolphin_agg2$correct))\n\nggplot(data = dolphin_agg2) +\n  geom_point(aes(x = condition, y = correct_numeric, color = condition), \n             # we add a little bit of jitter to make the points better visible\n             position = position_jitter(height = 0.02, width = 0.1), alpha = 0.2) \n```\n:::\n\n\n\n::: callout-caution\n**Exercise 1f**\n\nRun the appropriate generalized linear model in `brms` that predicts `correct` responses based on `condition`. Extract the posterior means and 95% CrIs for the effect of `condition` on `correct` and plot them as points and whiskers into one plot superimposed on the data.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nGlmMdl2 <- brm(correct ~ condition, \n                 dolphin_agg2, cores = 4,\n              family = \"bernoulli\")\nGlmMdl2\n\n# extract posterior means for model coefficients\npredicted_values <- GlmMdl2 %>%\n  spread_draws(b_Intercept, b_conditionTypical) %>%\n  # transform into proportion space\n  mutate(Atypical = plogis(b_Intercept),\n         Typical = plogis(b_Intercept + b_conditionTypical)\n         ) %>%\n  select(Atypical, Typical) %>% \n  gather(parameter, posterior) %>% \n  group_by(parameter) %>%\n  summarise(mean = mean(posterior, na.rm = TRUE),\n            lower = quantile(posterior, prob = 0.025),\n            upper = quantile(posterior, prob = 0.975)\n            ) \n\n# plot predicted values against data\nggplot(data = predicted_values) +\n  geom_point(data = dolphin_agg2, aes(x = condition, y = correct_numeric, color = condition), \n             # we add a little bit of jitter to make the points better visible\n             position = position_jitter(height = 0.02, width = 0.1), alpha = 0.2) +\n  geom_errorbar(aes(x = parameter, ymin = lower, ymax = upper), \n                width = 0.1, color = \"black\") +\n  geom_point(aes(x = parameter, y = mean, fill = parameter),\n             size = 4, color = \"black\", pch = 21) +\n  ylab(\"Predicted prob of correct responses\")\n```\n:::\n\n\n\n# Exercise 2: Poisson reduction\n\nWe will continue to use `dolphin_agg` in this exercise.\n\n::: callout-caution\n**Exercise 2b**\n\nPlot the relationship between `xpos_flips` and `log_RT_s` in a scatterplot and visually differentiate between `condition`s as you see fit.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nggplot(data = dolphin_agg) +\n  geom_point(aes(x = log_RT_s, y = xpos_flips, color = condition), \n             # we add a little bit of jitter to make the points better visible\n             position = position_jitter(height = 0.2), alpha = 0.2) +\n  ylim(-1,8) +\n  xlim(-5,10)\n```\n:::\n\n\n::: callout-caution\n**Exercise 2b**\n\nRun an appropriate generalized regression model for xflips with `brms` to predict `xpos_flips` based on `log_RT_s`, `condition`, and their two-way interaction.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nGlmMdl3 <- brm(xpos_flips ~ log_RT_s * condition, \n                 dolphin_agg, cores = 4,\n              family = \"poisson\")\nGlmMdl3\n```\n:::\n\n\n::: callout-caution\n**Exercise 2c**\n\nExtract the posterior means and 95% CrIs across a range of representative values of log_RT_s (see walkthrough) for both conditions and plot them against the data (as done before in walkthrough and exercise 1).\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\npredicted_Poisson_values <- GlmMdl3 %>%\n  spread_draws(b_Intercept, b_log_RT_s, b_conditionTypical, `b_log_RT_s:conditionTypical`) %>%\n  # make a list of relevant value range of logRT\n  mutate(log_RT = list(seq(-5, 10, 0.5))) %>% \n  unnest(log_RT) %>%\n  mutate(pred_atypical = exp(b_Intercept + b_log_RT_s * log_RT),\n         pred_typical = exp(b_Intercept + b_log_RT_s * log_RT +\n                              b_conditionTypical + `b_log_RT_s:conditionTypical` * log_RT)) %>%\n  group_by(log_RT) %>%\n  summarise(pred_atypical_m = mean(pred_atypical, na.rm = TRUE),\n            pred_atypical_low = quantile(pred_atypical, prob = 0.025),\n            pred_atypical_high = quantile(pred_atypical, prob = 0.975),\n            pred_typical_m = mean(pred_typical, na.rm = TRUE),\n            pred_typical_low = quantile(pred_typical, prob = 0.025),\n            pred_typical_high = quantile(pred_typical, prob = 0.975)) \n\n\nggplot(data = predicted_Poisson_values, aes(x = log_RT)) +\n  geom_point(data = dolphin_agg, aes(x = log_RT_s, y = xpos_flips, color = condition), \n             position = position_jitter(height = 0.2), alpha = 0.2) +\n  geom_ribbon(aes(ymin = pred_atypical_low, ymax = pred_atypical_high), alpha = 0.1) +\n  geom_ribbon(aes(ymin = pred_typical_low, ymax = pred_typical_high), alpha = 0.1) +\n  geom_line(aes(y = pred_atypical_m), color = \"#E69F00\", size = 2) +\n  geom_line(aes(y = pred_typical_m),color = \"#56B4E9\", size = 2) +\n  ylab(\"Predicted prob of xflips\") +\n  ylim(-1,10) +\n  xlim(-3,6)\n```\n:::\n\n\n\n# Exercise 3: Logistic regression with binomial likelihood\n\nBinary logistic regression assumes that the outcome variable comes from a Bernoulli distribution which is a special case of a binomial distribution where the number of trial $n = 1$ and thus the outcome variable can only be 1 or 0. In contrast, binomial logistic regression assumes that the number of the target events follows a binomial distribution with $n$ trials and probability $q$. Read up on Binomial data with `brms` here: https://www.rensvandeschoot.com/tutorials/generalised-linear-models-with-brms/\n\nTake the following subset of the `dolphin` data frame that only contains `correct` responses (= `1`). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set up data frame\ndolphin_sub <- dolphin %>% \n  filter(correct == 1) %>% \n  mutate(straight = (ifelse(prototype_label == \"straight\", 1, 0)),\n         log_RT_s = scale(log(RT)))\n```\n:::\n\n\n\n::: callout-caution\n**Exercise 3a**\n\nFor each `subject_id` in each `group`, aggregate the mean log_RT_s, the number of trials that are classified as `straight` trajectories, and the total number of trials. Plot the proportion of trials that are classified as `straight` (vs. all trials) trajectories for each subject.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# set up data frame\ndolphin_agg3 <- dolphin_sub %>% \n  group_by(subject_id, group) %>% \n  summarize(log_RT_s = mean(log_RT_s),\n            straights = sum(straight),\n            total = n()) \n\n# plot predicted values against data\nggplot(data = dolphin_agg3) +\n  geom_point(aes(x = log_RT_s, y = straights/total, color = group), size = 2, alpha = 0.5) +\n  ylab(\"Proportion of straight trajs\") +\n  ylim(0,1) +\n  xlim(-2.5,2.5)\n```\n:::\n\n\n::: callout-caution\n**Exercise 3b**\n\nFormulate a binomial logistic regression model to predict the proportion of straight trajectories based on `log_RT_s`, `group`, and their two-way interaction. Note that these proportional data are not assumed to be generated by a Bernoulli distribution, but a binomial distribution. Take that into account by setting `family = binomial(link = \"logit\")`.\n\nExtract posterior means and 95% CrIs for the effect of `log_RT_s` for both `group`s and plot them across a representative range of log_RT_s (as done before in this week).\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# We specify both the number of target events (straights) and the total number of trials (total) wrapped in trials(), which are separated by |. In addition, the family should be “binomial” instead of “bernoulli”.\nGlmMdl4 <- brm(\n  straights | trials(total) ~ log_RT_s * group,  \n  data = dolphin_agg3, \n  family = binomial(link = \"logit\"))\n\nsummary(GlmMdl4)\n\n# extract posteriors means and 95% CrIs\npredicted_values <- GlmMdl4 %>%\n  spread_draws(b_Intercept, b_log_RT_s, b_grouptouch, `b_log_RT_s:grouptouch`) %>%\n  # make a list of relevant value range of logRT\n  mutate(log_RT = list(seq(-3, 3, 0.2))) %>% \n  unnest(log_RT) %>%\n  # transform into proportion space\n  mutate(pred_click = plogis(b_Intercept + b_log_RT_s * log_RT),\n         pred_touch = plogis(b_Intercept + b_log_RT_s * log_RT +\n                               b_grouptouch + `b_log_RT_s:grouptouch` * log_RT)\n         ) %>%\n  group_by(log_RT) %>%\n  summarise(pred_click_m = mean(pred_click, na.rm = TRUE),\n            pred_click_low = quantile(pred_click, prob = 0.025),\n            pred_click_high = quantile(pred_click, prob = 0.975),\n            pred_touch_m = mean(pred_touch, na.rm = TRUE),\n            pred_touch_low = quantile(pred_touch, prob = 0.025),\n            pred_touch_high = quantile(pred_touch, prob = 0.975)\n            ) \n\n# plot predicted values against data\nggplot(data = predicted_values) +\n  geom_point(data = dolphin_agg3,\n             aes(x = log_RT_s, y = straights / total, color = group),\n             alpha = 0.2, size = 2) +\n  geom_ribbon(aes(x = log_RT, ymin = pred_click_low, ymax = pred_click_high), alpha = 0.2) +\n  geom_ribbon(aes(x = log_RT, ymin = pred_touch_low, ymax = pred_touch_high), alpha = 0.2) +\n  geom_line(aes(x = log_RT, y = pred_click_m), color = \"#E69F00\", size = 2) +\n  geom_line(aes(x = log_RT, y = pred_touch_m), color = \"#56B4E9\", size = 2) +\n  ylab(\"Predicted prob of straight trajs\") +\n  ylim(0,1) +\n  xlim(-2.5,2.5)\n```\n:::\n\n\n::: callout-caution\n**Exercise 3c**\n\nNow compare the results from this analysis to the results from the model 1b above which you plotted in 1d. How do the model results differ and why could that be? (Feel free to explore the data to understand what is going on)\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# Answer: The model in 1b suggested a negative coefficient of reaction time, i.e. slower responses lead to less straight trajectories. The model here suggests a positive coefficient for reaction time, i.e. slower responses lead to more straight trajectories. Given the data, the model, and the priors, this effect is compelling for at least the click group. \n\n# A major difference in the two analyses is that the former analysis looked at all data and disregarded that responses came from clusters of sources. For example, responses that come from one and the same participant are dependent on each other because participants might differ in characteristics relevant to the task, like how fast they move and how many times they move to the target in a straight trajectory. The latter analysis aggregated participants behavior by looking at the proportion of straight trajectories within each subject, thus one data point corresponds to one participant, resulting in data points being independent (at least regarding the participant identity). If all participants showed a negative effect of reaction time on the likelihood of straight trajectories, but participants systematically differ in terms of their baseline correlation between reaction time and likelihood of producing straight trajectories in the opposite direction (positive relationship), we might get discrepancies between these different models. What we ultimately need is to take multiple levels of the data into account simultaneously, which is the topic of next week.\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}