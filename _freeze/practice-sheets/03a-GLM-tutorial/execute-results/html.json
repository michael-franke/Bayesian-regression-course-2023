{
  "hash": "e5cb0f03b73dbc6ed862c6af74ab57a3",
  "result": {
    "markdown": "---\ntitle: \"Bayesian regression: theory & practice\"\nsubtitle: \"03a: Generalized linear models\"\nauthor: \"Michael Franke\"\nformat: html\neditor: visual\nexecute:\n  error: false\n  warning: false\n  message: false\ncallout-appearance: simple\n---\nHere is code to load (and if necessary, install) required packages, and to set some global options (for plotting and efficient fitting of Bayesian models).\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# install packages from CRAN (unless installed)\npckgs_needed <- c(\n  \"tidyverse\",\n  \"brms\",\n  \"remotes\",\n  \"tidybayes\"\n)\npckgs_installed <- installed.packages()[,\"Package\"]\npckgs_2_install <- pckgs_needed[!(pckgs_needed %in% pckgs_installed)]\nif(length(pckgs_2_install)) {\n  install.packages(pckgs_2_install)\n} \n\n# install additional packages from GitHub (unless installed)\nif (! \"aida\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/aida-package\")\n}\nif (! \"faintr\" %in% pckgs_installed) {\n  remotes::install_github(\"michael-franke/faintr\")\n}\nif (! \"cspplot\" %in% pckgs_installed) {\n  remotes::install_github(\"CogSciPrag/cspplot\")\n}\n\n# load the required packages\nx <- lapply(pckgs_needed, library, character.only = TRUE)\nlibrary(aida)\nlibrary(faintr)\nlibrary(cspplot)\n\n# these options help Stan run faster\noptions(mc.cores = parallel::detectCores())\n\n# use the CSP-theme for plotting\ntheme_set(theme_csp())\n\n# global color scheme from CSP\nproject_colors = cspplot::list_colors()[c(1,3,4,5,2,6:14),\"hex\", drop = TRUE]\n\n# setting theme colors globally\nscale_colour_discrete <- function(...) {\n  scale_colour_manual(..., values = project_colors)\n}\nscale_fill_discrete <- function(...) {\n   scale_fill_manual(..., values = project_colors)\n}\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin <- aida::data_MT\n```\n:::\n\n\nThis tutorial covers common types of generalized linear regression models:\n\n-   logistic regression\n-   multinomial regression\n-   ordinal regression\n-   Poisson regression\n\n# Logistic regression\n\nOur hypothesis is that typical examples are easier to classify, so they should have higher accuracy than atypical ones. We are also interested in additional effects of `group` on accuracy.\n\nAs usual, we begin by plotting the relevant data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum_stats <- dolphin |> \n  group_by(group, condition) |> \n  tidyboot::tidyboot_mean(correct) |> \n  rename(accuracy = empirical_stat)\n  \nsum_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 Ã— 7\n# Groups:   group [2]\n  group condition     n accuracy ci_lower  mean ci_upper\n  <chr> <chr>     <int>    <dbl>    <dbl> <dbl>    <dbl>\n1 click Atypical    318    0.874    0.836 0.874    0.908\n2 click Typical     689    0.964    0.950 0.964    0.977\n3 touch Atypical    330    0.909    0.875 0.908    0.938\n4 touch Typical     715    0.941    0.924 0.941    0.958\n```\n:::\n\n```{.r .cell-code}\nsum_stats |> \n  ggplot(aes(x = condition, y = accuracy, group = group, color = group)) +\n  geom_line(size = 1, position = position_dodge(0.2)) +\n  geom_point(size = 3, position = position_dodge(0.2)) +\n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), \n                width = 0.1, size = 0.35, position = position_dodge(0.2))\n```\n\n::: {.cell-output-display}\n![](03a-GLM-tutorial_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nVisually, there might be a hint that typical trials had higher accuracy, but we cannot judge with the naked eye whether this is substantial.\n\nA logistic regression, regressing `correct` against `group * condition`, may tell us more. To run the logistic regression, we must tell the `brms:brm()` that we want to treat 0 and 1 as categories. To be sure, and also to directly dictate which of the two categories is the reference level, we use a factor (of strings) with explicit ordering.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_logistic <- brm(\n  formula = correct ~ group * condition,\n  data = dolphin |> \n    mutate(correct = factor(ifelse(correct, \"correct\", \"incorrect\"),\n                            levels = c(\"incorrect\", \"correct\"))),\n  family = bernoulli()\n)\n\nsummary(fit_logistic)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: correct ~ group * condition \n   Data: mutate(dolphin, correct = factor(ifelse(correct, \" (Number of observations: 2052) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nIntercept                       1.95      0.17     1.63     2.29 1.00     2176\ngrouptouch                      0.37      0.26    -0.13     0.90 1.00     1730\nconditionTypical                1.35      0.26     0.83     1.86 1.00     1627\ngrouptouch:conditionTypical    -0.88      0.35    -1.56    -0.18 1.00     1402\n                            Tail_ESS\nIntercept                       2557\ngrouptouch                      2250\nconditionTypical                1595\ngrouptouch:conditionTypical     2079\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nTo test whether typical examples had credibly higher accuracy, the `faintr` package can be used like so:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_groups(\n  fit_logistic,\n  higher = condition == \"Typical\",\n  lower  = condition == \"Atypical\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOutcome of comparing groups: \n * higher:  condition == \"Typical\" \n * lower:   condition == \"Atypical\" \nMean 'higher - lower':  0.9063 \n95% HDI:  [ 0.5439 ; 1.27 ]\nP('higher - lower' > 0):  1 \nPosterior odds:  Inf \n```\n:::\n:::\n\n\nBased on these results, we may conclude that, given the model and the data, we should believe that typical examples had higher accuracy.\n\n::: callout-caution\n**Exercise 1a**\n\nTest whether there is reason to believe, given model and data, that the touch group was more accurate than the click group. (After all, the click group could change their minds until the very last moment.)\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\ncompare_groups(\n  fit_logistic,\n  higher = group == \"click\",\n  lower  = group == \"touch\"\n)\n\n# there is no reason to believe (given model and data) that this conjecture is true\n```\n:::\n\n\n::: callout-caution\n**Exercise 1b**\n\nIf you look back at the plot of accuracy, it looks as if the change from atypical to typical condition had a reverse effect for the click and the touch group, i.e., it seems that ther is an interaction between these two variables (`group` and `condition`). Use the function `brms::hypothesis()` to examin the interaction term of the model fit. What do you conclude from this?\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\nbrms::hypothesis(fit_logistic, \"grouptouch:conditionTypical < 0\")\n\n# given model and data, it is very plausible to believe that there is an interaction between these two variables.\n```\n:::\n\n\n# Multinomial regression\n\n## Explanation\n\nIn multinomial regression the predicted variable is categorical with more than two levels: $c_1, \\dots, c_k$, $k > 2$. We want to predict probabilities for each category $p_1, \\dots, p_k$ (with some linear predictors, more on this in a moment). To obtain the probabilities, we estimate a set of weights (so-called *logits*): $s_1, \\dots, s_k$. By default, we set $s_1 = 0$. (We only need $k-1$ numbers to define a $k$-place probability vector (given that it must sum to one).) For all $1 \\le i \\le k$, we define the probability $p_i$ of category $i$ via the following (so-called *soft-max* operation):\n\n$$\np_i = \\frac{\\exp s_i}{ \\sum_{j=1}^k \\exp s_j}\n$$\n\nThis entails that for every $1 < i \\le k$, the score $s_i$ can be interpreted as the log-odds of category $c_i$ over the reference category $c_1$:\n\n$$\ns_i = \\log \\frac{p_i}{p_1}\n$$\n\nFinally, we do not just estimate any-old vector of logits, but we assume that each logit $s_i$ ($1 < i \\le k$) is estimated as a linear predictor (based on the usual linear regression predictor coefficients, appropriate to the type of the $l$ explanatory variables):\n\n$$\ns_i = \\beta^i_0 + \\beta^i_1 x_1 + \\beta^i_2 x_2 + \\dots + \\beta^i_l x_l\n$$\n\nTwo things are important for interpreting the outcome of a multinomial regression fit:\n\n1.  each category (beyond the reference category) receives its own (independent) set of regression coefficients;\n2.  the linear predictor predictor $s_i$ for category $c_i$ can be interpreted as the log-odds of the $i$-th category over the first, reference category.\n\n## Example\n\nOur next research question is slightly diffuse: we want to explore whether the distribution of trajectory types is affected by whether the correct target was on the right or the left. We only consider three types of categories (curved, straight and 'change of mind') and prepare the data to also give us the information whether the 'correct' target was left or right.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin_prepped <-\n  dolphin |>\n  mutate(\n    prototype_label = case_when(\n     prototype_label %in% c('curved', 'straight') ~ prototype_label,\n     TRUE ~ 'CoM'\n    ),\n    prototype_label = factor(prototype_label,\n                             levels = c('straight', 'curved', 'CoM')),\n    target_position = ifelse(category_left == category_correct, \"left\", \"right\")\n    )\n```\n:::\n\n\nThe relevant data now looks as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin_prepped |> \n  select(prototype_label, target_position)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,052 Ã— 2\n   prototype_label target_position\n   <fct>           <chr>          \n 1 straight        left           \n 2 straight        right          \n 3 curved          right          \n 4 curved          left           \n 5 CoM             left           \n 6 CoM             right          \n 7 CoM             right          \n 8 straight        left           \n 9 straight        left           \n10 straight        left           \n# â€¦ with 2,042 more rows\n```\n:::\n:::\n\n\nThe counts and proportions we care about are these:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum_stats <- dolphin_prepped |> \n  count(target_position, prototype_label) |>\n  group_by(target_position) |> \n  mutate(proportion = n / sum(n))\n\nsum_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 Ã— 4\n# Groups:   target_position [2]\n  target_position prototype_label     n proportion\n  <chr>           <fct>           <int>      <dbl>\n1 left            straight          751     0.734 \n2 left            curved            136     0.133 \n3 left            CoM               136     0.133 \n4 right           straight          793     0.771 \n5 right           curved             93     0.0904\n6 right           CoM               143     0.139 \n```\n:::\n:::\n\n\nAnd here is a plot that might be useful to address your current issue:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum_stats |> \n  ggplot(aes(x = prototype_label, y = proportion, fill = prototype_label)) +\n  geom_col() +\n  facet_grid(. ~ target_position)\n```\n\n::: {.cell-output-display}\n![](03a-GLM-tutorial_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nIt is hard to say from visual inspection alone, whether there are any noteworthy differences. We might consider the following:\n\n- **Conjecture:** the /difference/ in probability between straight vs curved is higher when the target is on the right than when it is on the left. \n\nThis is not a real \"research hypothesis\" but a conjecture about the data. Let's still run a multinomial regression model to test address this conjecture.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_multinom <- brm(\n  formula = prototype_label ~ target_position,\n  data = dolphin_prepped,\n  family = categorical()\n)\n```\n:::\n\n\nThe summary of this model fit is a bit unwieldy:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit_multinom)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Family: categorical \n  Links: mucurved = logit; muCoM = logit \nFormula: prototype_label ~ target_position \n   Data: dolphin_prepped (Number of observations: 2052) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nPopulation-Level Effects: \n                              Estimate Est.Error l-95% CI u-95% CI Rhat\nmucurved_Intercept               -1.71      0.09    -1.90    -1.53 1.00\nmuCoM_Intercept                  -1.71      0.09    -1.89    -1.54 1.00\nmucurved_target_positionright    -0.43      0.15    -0.73    -0.15 1.00\nmuCoM_target_positionright       -0.00      0.13    -0.25     0.25 1.00\n                              Bulk_ESS Tail_ESS\nmucurved_Intercept                4655     3332\nmuCoM_Intercept                   3649     3016\nmucurved_target_positionright     3844     3151\nmuCoM_target_positionright        3772     2960\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n:::\n\n\nFor better visibility here is a plot of the posteriors over relevant model parameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# there MUST be a nicer way of doing this, but ...\nordered_names <- c(\n  \"b_mucurved_Intercept\", \n  \"b_muCoM_Intercept\",\n  \"b_mucurved_target_positionright\",\n  \"b_muCoM_target_positionright\"\n)\n\nfit_multinom |> \n  tidybayes::tidy_draws() |> \n  pivot_longer(cols = starts_with(\"b_\")) |> \n  select(name, value) |> \n  mutate(name = factor(name, levels = rev(ordered_names))) |> \n  ggplot(aes(x = value, y = name)) +\n  tidybayes::stat_halfeye() +\n  geom_vline(aes(xintercept = 0), color = project_colors[3], alpha= 1, size = 1)\n```\n\n::: {.cell-output-display}\n![](03a-GLM-tutorial_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n::: callout-caution\n**Exercise 2a**\n\nLook at the names of the coefficients in the fit summary to find out:What is the reference level for the categorical predictor variable?\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# It's the 'left' position, because there is a coefficient for the 'right' position.\n```\n:::\n\n\n::: callout-caution\n**Exercise 2b**\n\nLook at the names of the coefficients in the fit summary to find out: What is the reference level of the categories to be predicted in the multinomial model?\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# The reference category is 'straight' because we have regression coeffiecient for all but the 'straight' category.\n```\n:::\n\n\n\n::: callout-caution\n**Exercise 2c**\n\nCan you extract information about our conjecture from this plot (or the summary of the model fit)?\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# Yes! Our conjecture is about the difference in probability of the 'straight' vs he 'curved' category. This difference is directly encoded in regression coefficients. Concretely, the coefficient 'mucurved_Intercept' gives us the log odds of the 'straight' vs' the 'curved' category for the 'left'-position cases. The difference of log odds for the 'right'-position cases is simply the coefficient 'mucurved_target_positionright'. The is credibly smaller than zero (by a margin), so we may conclude that model and data provide support for our conjecture.\n```\n:::\n\n\n::: callout-caution\n**Exercise 2d**\n\nUse the postrior means of the regression coefficients to compute the corresponding scores $s_i$ and class probabilities $c_i$. Compare these to the observed frequencies.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show solution\"}\n# extract mean posteriors\nposterior_means <- fit_multinom |> tidybayes::summarise_draws() |> \n  select(variable, mean) |> \n  pivot_wider(names_from = variable, values_from = mean)\n\nas.numeric(posterior_means, names = colnames(posterior_means))  \n\nscores_left <- c(\n  0,\n  posterior_means[1,\"b_mucurved_Intercept\"] |> as.numeric(),\n  posterior_means[1,\"b_muCoM_Intercept\"] |> as.numeric()\n)\n\nscores_right <- c(\n  0,\n  posterior_means[1,\"b_mucurved_Intercept\"] |> as.numeric() + posterior_means[1,\"b_mucurved_target_positionright\"] |> as.numeric(),\n  posterior_means[1,\"b_muCoM_Intercept\"] |> as.numeric() + posterior_means[1,\"b_muCoM_target_positionright\"] |> as.numeric()\n)\n\nprobabilities_left <- prop.table(exp(scores_left))\nprobabilities_right <- prop.table(exp(scores_right))\n\nsum_stats |> ungroup() |> \n  mutate(prediction = c(probabilities_left, probabilities_right))\n```\n:::\n\n\n# Ordinal regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin_prepped2 <- dolphin_prepped |> \n    mutate(prototype_label = factor(prototype_label, ordered = T))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndolphin_prepped2 |> \n  ggplot(aes(x = MAD, y = prototype_label, color = prototype_label)) +\n  geom_jitter(alpha = 0.3,height = 0.3, width = 0)\n```\n\n::: {.cell-output-display}\n![](03a-GLM-tutorial_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ordinal <- brm(\n  formula = prototype_label ~ MAD,\n  data = dolphin_prepped2,\n  family = cumulative()\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_ordinal |> \n  tidybayes::gather_draws(b_MAD) |> \n  ggplot(aes(x = .value, y = .variable)) +\n  tidybayes::stat_halfeye() +\n  ylab(\"\") + xlab(\"\") + ggplot2::xlim(0,0.03)\n```\n\n::: {.cell-output-display}\n![](03a-GLM-tutorial_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbrms::hypothesis(fit_ordinal, \"MAD > 0\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHypothesis Tests for class b:\n  Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n1  (MAD) > 0     0.02         0     0.02     0.03        Inf         1    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n```\n:::\n:::\n\n\n\n# Poisson regression\n",
    "supporting": [
      "03a-GLM-tutorial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}